{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp cluster_grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster_grid_search module\n",
    "\n",
    "> Functions for optimising clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn import cluster\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "from sklearn.base import ClusterMixin\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) is used below as an example of some data to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris(as_frame=True)\n",
    "X = iris.data\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def assign_cluster_labels(\n",
    "    data_to_cluster: Union[pd.DataFrame, np.ndarray, list], # Data points to cluster\n",
    "    cluster_model: ClusterMixin, # Sk-learn clustering model. Must be specified in the format `cluster.model`, e.g `cluster.KMeans`\n",
    "    model_kwargs: dict, # Keyword arguments for sk-learn clustering model\n",
    ") -> np.ndarray: # Label assignments\n",
    "    \"\"\"Assigns cluster labels to `data_to_cluster` using specified `cluster_model`\"\"\"\n",
    "    cluster_model = cluster_model(**model_kwargs)\n",
    "    return cluster_model.fit_predict(data_to_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### assign_cluster_labels\n",
       "\n",
       ">      assign_cluster_labels\n",
       ">                             (data_to_cluster:Union[pandas.core.frame.DataFrame\n",
       ">                             ,numpy.ndarray,list],\n",
       ">                             cluster_model:sklearn.base.ClusterMixin,\n",
       ">                             model_kwargs:dict)\n",
       "\n",
       "Assign cluster labels to `data_to_cluster` using specified `cluster_model`\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| data_to_cluster | typing.Union[pandas.core.frame.DataFrame, numpy.ndarray, list] | Data points to cluster |\n",
       "| cluster_model | ClusterMixin | Sk-learn clustering model. Must be specified in the format `cluster.model`, e.g `cluster.KMeans` |\n",
       "| model_kwargs | dict | Keyword arguments for sk-learn clustering model |\n",
       "| **Returns** | **ndarray** | **Label assignments** |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer at 0x14cf275e0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(assign_cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `assign_cluster_labels` function to assign cluster labels. The function can accept any sk-learn clustering model and you can specify any parameters for the model in the `model_kwargs` argument.\n",
    "See an example below that assigns labels to the iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 3, 3, 3, 0, 3, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 3,\n",
       "       0, 0, 3, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 3, 0, 3, 3, 3,\n",
       "       0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 2, 3, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       3, 3, 2, 3, 3, 2, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2,\n",
       "       2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 3, 3, 2, 3], dtype=int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = assign_cluster_labels(X, cluster.KMeans, {\"n_clusters\": 4})\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette Score -- Validity of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_silhouette_avg(\n",
    "    data: Union[pd.DataFrame, np.ndarray, list], # The data that was used for the clustering\n",
    "    cluster_labels: np.ndarray, # Cluster labels\n",
    ") -> float: # Average silhouette score\n",
    "    \"\"\"Calculate the average silhouette score\"\"\"\n",
    "    return silhouette_score(data, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### calculate_silhouette_avg\n",
       "\n",
       ">      calculate_silhouette_avg (data:Union[numpy.__array_like._SupportsArray[nu\n",
       ">                                mpy.dtype],numpy.__nested_sequence._NestedSeque\n",
       ">                                nce[numpy.__array_like._SupportsArray[numpy.dty\n",
       ">                                pe]],bool,int,float,complex,str,bytes,numpy.__n\n",
       ">                                ested_sequence._NestedSequence[Union[bool,int,f\n",
       ">                                loat,complex,str,bytes]]],\n",
       ">                                cluster_labels:numpy.ndarray)\n",
       "\n",
       "Calculate the average silhouette score\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| data | typing.Union[numpy._typing._array_like._SupportsArray[numpy.dtype], numpy._typing._nested_sequence._NestedSequence[numpy._typing._array_like._SupportsArray[numpy.dtype]], bool, int, float, complex, str, bytes, numpy._typing._nested_sequence._NestedSequence[typing.Union[bool, int, float, complex, str, bytes]]] | The data that was used for the clustering |\n",
       "| cluster_labels | ndarray | Cluster labels |\n",
       "| **Returns** | **float** | **Average silhouette score** |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer at 0x14ce3e670>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(calculate_silhouette_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the average [silhouette score](https://www.sciencedirect.com/science/article/pii/0377042787901257?via%3Dihub) as a measure of the validity of our clusters. It can be used to select an approriate number of clusters. Values range from -1 to +1, where a higher value indicates that the points are on average far away from clusters that aren't their own. Negative values indicate that there is a lot of overlap between the clusters.\n",
    "\n",
    "Below is an example using the `calculate_silhouette_avg` on the iris example dataset and the assigned cluster labels from our clustering above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49805050499728776"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_silhouette_avg(X, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def grid_search(\n",
    "    data_to_cluster: Union[pd.DataFrame, np.ndarray, list], # Data points to cluster\n",
    "    cluster_models: list, # List of Sk-learn clustering models to iterate through. Each model must be specified in the format `cluster.model`, e.g `cluster.KMeans`\n",
    "    model_kwargs_list: list, # List of dicts of keyword arguments for the sk-learn clustering models to iterate through.\n",
    "    highlight: bool, # True to highlight highest avg_silhouette_score\n",
    "    sort: bool, # True to sort by highest avg_silhouette_score\n",
    ") -> pd.DataFrame: # Table showing avg_silhouette_score for each model and parameter specified\n",
    "    \"\"\"Perform grid search for the specified clustering models and parameters\"\"\"\n",
    "    cluster_model = []\n",
    "    model_parameters = []\n",
    "    silhouette_score = []\n",
    "    for model, model_kwargs in tqdm(zip(cluster_models, model_kwargs_list)):\n",
    "        for parameters in tqdm(ParameterGrid(model_kwargs)):\n",
    "            labels = assign_cluster_labels(\n",
    "                data_to_cluster,\n",
    "                model,\n",
    "                parameters\n",
    "            )\n",
    "            avg_silhouette_score = calculate_silhouette_avg(\n",
    "                data_to_cluster,\n",
    "                labels\n",
    "            )\n",
    "            cluster_model.append(str(model).split(\".\")[-1][:-2])\n",
    "            model_parameters.append(parameters)\n",
    "            silhouette_score.append(avg_silhouette_score)\n",
    "    results = pd.DataFrame.from_dict({\n",
    "        \"cluster_model\": cluster_model,\n",
    "        \"model_params\": model_parameters,\n",
    "        \"avg_silhouette_score\": silhouette_score\n",
    "    })\n",
    "    if sort:\n",
    "        results = results.sort_values(\"avg_silhouette_score\", ascending=False)\n",
    "    if highlight:\n",
    "        results = results.style.highlight_max(\n",
    "            subset = [\"avg_silhouette_score\"],\n",
    "            color = 'lightgreen', axis = 0\n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### grid_search\n",
       "\n",
       ">      grid_search\n",
       ">                   (data_to_cluster:Union[pandas.core.frame.DataFrame,numpy.nda\n",
       ">                   rray,list], cluster_models:list, model_kwargs_list:list,\n",
       ">                   highlight:bool, sort:bool)\n",
       "\n",
       "Perform grid search for the specified clustering models and parameters\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| data_to_cluster | typing.Union[pandas.core.frame.DataFrame, numpy.ndarray, list] | Data points to cluster |\n",
       "| cluster_models | list | List of Sk-learn clustering models to iterate through. Each model must be specified in the format `cluster.model`, e.g `cluster.KMeans` |\n",
       "| model_kwargs_list | list | List of dicts of keyword arguments for the sk-learn clustering models to iterate through. |\n",
       "| highlight | bool | True to highlight highest avg_silhouette_score |\n",
       "| sort | bool | True to sort by highest avg_silhouette_score |\n",
       "| **Returns** | **DataFrame** | **Table showing avg_silhouette_score for each model and parameter specified** |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer at 0x1513704f0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `grid_search` function to optimise for the highest silhouette score across different sk-learn clustering models and different parameters. An example is below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cluster models list and model kwargs list that will be passed into `grid_search` function should be in the form below. The order of the two lists should relate to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_models = [\n",
    "    cluster.KMeans,\n",
    "    cluster.AffinityPropagation\n",
    "]\n",
    "\n",
    "model_kwargs_list = [\n",
    "    {\"n_clusters\": [2, 3, 4], \"init\": [\"k-means++\", \"random\"]},\n",
    "    {\"damping\": [0.6, 0.7, 0.8]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the `grid_search` function to perform grid search over the models and kwargs to find the highest silhouette score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|                                               | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "100%|███████████████████████████████████████| 6/6 [00:00<00:00, 31.68it/s]\u001b[A\n",
      "1it [00:00,  5.14it/s]\n",
      "100%|███████████████████████████████████████| 3/3 [00:00<00:00, 67.43it/s]\u001b[A\n",
      "2it [00:00,  8.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_81fe8_row0_col2, #T_81fe8_row1_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_81fe8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_81fe8_level0_col0\" class=\"col_heading level0 col0\" >cluster_model</th>\n",
       "      <th id=\"T_81fe8_level0_col1\" class=\"col_heading level0 col1\" >model_params</th>\n",
       "      <th id=\"T_81fe8_level0_col2\" class=\"col_heading level0 col2\" >avg_silhouette_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_81fe8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_81fe8_row0_col0\" class=\"data row0 col0\" >KMeans</td>\n",
       "      <td id=\"T_81fe8_row0_col1\" class=\"data row0 col1\" >{'init': 'k-means++', 'n_clusters': 2}</td>\n",
       "      <td id=\"T_81fe8_row0_col2\" class=\"data row0 col2\" >0.681046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81fe8_level0_row1\" class=\"row_heading level0 row1\" >3</th>\n",
       "      <td id=\"T_81fe8_row1_col0\" class=\"data row1 col0\" >KMeans</td>\n",
       "      <td id=\"T_81fe8_row1_col1\" class=\"data row1 col1\" >{'init': 'random', 'n_clusters': 2}</td>\n",
       "      <td id=\"T_81fe8_row1_col2\" class=\"data row1 col2\" >0.681046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81fe8_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "      <td id=\"T_81fe8_row2_col0\" class=\"data row2 col0\" >KMeans</td>\n",
       "      <td id=\"T_81fe8_row2_col1\" class=\"data row2 col1\" >{'init': 'k-means++', 'n_clusters': 3}</td>\n",
       "      <td id=\"T_81fe8_row2_col2\" class=\"data row2 col2\" >0.552819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81fe8_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_81fe8_row3_col0\" class=\"data row3 col0\" >KMeans</td>\n",
       "      <td id=\"T_81fe8_row3_col1\" class=\"data row3 col1\" >{'init': 'random', 'n_clusters': 3}</td>\n",
       "      <td id=\"T_81fe8_row3_col2\" class=\"data row3 col2\" >0.552819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81fe8_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_81fe8_row4_col0\" class=\"data row4 col0\" >KMeans</td>\n",
       "      <td id=\"T_81fe8_row4_col1\" class=\"data row4 col1\" >{'init': 'random', 'n_clusters': 4}</td>\n",
       "      <td id=\"T_81fe8_row4_col2\" class=\"data row4 col2\" >0.498051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81fe8_level0_row5\" class=\"row_heading level0 row5\" >2</th>\n",
       "      <td id=\"T_81fe8_row5_col0\" class=\"data row5 col0\" >KMeans</td>\n",
       "      <td id=\"T_81fe8_row5_col1\" class=\"data row5 col1\" >{'init': 'k-means++', 'n_clusters': 4}</td>\n",
       "      <td id=\"T_81fe8_row5_col2\" class=\"data row5 col2\" >0.497455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81fe8_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_81fe8_row6_col0\" class=\"data row6 col0\" >AffinityPropagation</td>\n",
       "      <td id=\"T_81fe8_row6_col1\" class=\"data row6 col1\" >{'damping': 0.7}</td>\n",
       "      <td id=\"T_81fe8_row6_col2\" class=\"data row6 col2\" >0.474338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81fe8_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_81fe8_row7_col0\" class=\"data row7 col0\" >AffinityPropagation</td>\n",
       "      <td id=\"T_81fe8_row7_col1\" class=\"data row7 col1\" >{'damping': 0.8}</td>\n",
       "      <td id=\"T_81fe8_row7_col2\" class=\"data row7 col2\" >0.468801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81fe8_level0_row8\" class=\"row_heading level0 row8\" >6</th>\n",
       "      <td id=\"T_81fe8_row8_col0\" class=\"data row8 col0\" >AffinityPropagation</td>\n",
       "      <td id=\"T_81fe8_row8_col1\" class=\"data row8 col1\" >{'damping': 0.6}</td>\n",
       "      <td id=\"T_81fe8_row8_col2\" class=\"data row8 col2\" >0.345462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1512d8a60>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search(\n",
    "    data_to_cluster=X,\n",
    "    cluster_models=cluster_models,\n",
    "    model_kwargs_list=model_kwargs_list,\n",
    "    sort=True,\n",
    "    highlight=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
